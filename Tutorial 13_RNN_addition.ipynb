{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RNN Addition Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addition questions: 50000\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "# Generate training and test data\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "# Vectorize training and test data\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far. \n",
    "    # This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 212us/step - loss: 1.8841 - acc: 0.3230 - val_loss: 1.7961 - val_acc: 0.3382\n",
      "Question   Prediction   Answer\n",
      "466+99     104          565     \u001b[91m ☒ \u001b[0m\n",
      "0+807      40           807     \u001b[91m ☒ \u001b[0m\n",
      "129+640    102          769     \u001b[91m ☒ \u001b[0m\n",
      "538+41     104          579     \u001b[91m ☒ \u001b[0m\n",
      "28+12      22           40      \u001b[91m ☒ \u001b[0m\n",
      "777+715    102          1492    \u001b[91m ☒ \u001b[0m\n",
      "63+307     104          370     \u001b[91m ☒ \u001b[0m\n",
      "270+782    102          1052    \u001b[91m ☒ \u001b[0m\n",
      "222+670    102          892     \u001b[91m ☒ \u001b[0m\n",
      "3+853      42           856     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 1.7275 - acc: 0.3624 - val_loss: 1.6536 - val_acc: 0.3826\n",
      "Question   Prediction   Answer\n",
      "1+872      180          873     \u001b[91m ☒ \u001b[0m\n",
      "95+856     106          951     \u001b[91m ☒ \u001b[0m\n",
      "676+39     772          715     \u001b[91m ☒ \u001b[0m\n",
      "34+555     576          589     \u001b[91m ☒ \u001b[0m\n",
      "3+171      110          174     \u001b[91m ☒ \u001b[0m\n",
      "80+35      104          115     \u001b[91m ☒ \u001b[0m\n",
      "37+756     772          793     \u001b[91m ☒ \u001b[0m\n",
      "167+738    100          905     \u001b[91m ☒ \u001b[0m\n",
      "695+0      100          695     \u001b[91m ☒ \u001b[0m\n",
      "170+368    800          538     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 156us/step - loss: 1.5633 - acc: 0.4119 - val_loss: 1.4705 - val_acc: 0.4427\n",
      "Question   Prediction   Answer\n",
      "6+643      661          649     \u001b[91m ☒ \u001b[0m\n",
      "193+20     234          213     \u001b[91m ☒ \u001b[0m\n",
      "19+76      11           95      \u001b[91m ☒ \u001b[0m\n",
      "6+923      904          929     \u001b[91m ☒ \u001b[0m\n",
      "293+760    103          1053    \u001b[91m ☒ \u001b[0m\n",
      "61+9       11           70      \u001b[91m ☒ \u001b[0m\n",
      "851+442    1238         1293    \u001b[91m ☒ \u001b[0m\n",
      "65+687     632          752     \u001b[91m ☒ \u001b[0m\n",
      "215+368    688          583     \u001b[91m ☒ \u001b[0m\n",
      "69+874     904          943     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 164us/step - loss: 1.3662 - acc: 0.4899 - val_loss: 1.2924 - val_acc: 0.5204\n",
      "Question   Prediction   Answer\n",
      "46+678     735          724     \u001b[91m ☒ \u001b[0m\n",
      "21+402     455          423     \u001b[91m ☒ \u001b[0m\n",
      "268+651    905          919     \u001b[91m ☒ \u001b[0m\n",
      "23+603     635          626     \u001b[91m ☒ \u001b[0m\n",
      "892+808    1666         1700    \u001b[91m ☒ \u001b[0m\n",
      "8+721      733          729     \u001b[91m ☒ \u001b[0m\n",
      "5+853      855          858     \u001b[91m ☒ \u001b[0m\n",
      "631+457    1056         1088    \u001b[91m ☒ \u001b[0m\n",
      "369+697    1006         1066    \u001b[91m ☒ \u001b[0m\n",
      "24+691     755          715     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 159us/step - loss: 1.2223 - acc: 0.5463 - val_loss: 1.1633 - val_acc: 0.5626\n",
      "Question   Prediction   Answer\n",
      "100+79     187          179     \u001b[91m ☒ \u001b[0m\n",
      "648+359    902          1007    \u001b[91m ☒ \u001b[0m\n",
      "945+791    1661         1736    \u001b[91m ☒ \u001b[0m\n",
      "835+4      830          839     \u001b[91m ☒ \u001b[0m\n",
      "30+102     146          132     \u001b[91m ☒ \u001b[0m\n",
      "397+976    1322         1373    \u001b[91m ☒ \u001b[0m\n",
      "377+761    1007         1138    \u001b[91m ☒ \u001b[0m\n",
      "556+2      567          558     \u001b[91m ☒ \u001b[0m\n",
      "932+893    1761         1825    \u001b[91m ☒ \u001b[0m\n",
      "579+2      572          581     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 1.0916 - acc: 0.5989 - val_loss: 1.0388 - val_acc: 0.6214\n",
      "Question   Prediction   Answer\n",
      "36+480     512          516     \u001b[91m ☒ \u001b[0m\n",
      "4+506      511          510     \u001b[91m ☒ \u001b[0m\n",
      "484+24     511          508     \u001b[91m ☒ \u001b[0m\n",
      "723+60     788          783     \u001b[91m ☒ \u001b[0m\n",
      "919+29     945          948     \u001b[91m ☒ \u001b[0m\n",
      "58+78      142          136     \u001b[91m ☒ \u001b[0m\n",
      "126+95     211          221     \u001b[91m ☒ \u001b[0m\n",
      "65+501     564          566     \u001b[91m ☒ \u001b[0m\n",
      "896+63     941          959     \u001b[91m ☒ \u001b[0m\n",
      "386+743    1107         1129    \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 166us/step - loss: 0.9927 - acc: 0.6406 - val_loss: 0.9650 - val_acc: 0.6538\n",
      "Question   Prediction   Answer\n",
      "10+222     237          232     \u001b[91m ☒ \u001b[0m\n",
      "882+4      889          886     \u001b[91m ☒ \u001b[0m\n",
      "637+94     733          731     \u001b[91m ☒ \u001b[0m\n",
      "30+767     793          797     \u001b[91m ☒ \u001b[0m\n",
      "698+16     711          714     \u001b[91m ☒ \u001b[0m\n",
      "6+527      531          533     \u001b[91m ☒ \u001b[0m\n",
      "51+721     773          772     \u001b[91m ☒ \u001b[0m\n",
      "984+28     1010         1012    \u001b[91m ☒ \u001b[0m\n",
      "4+556      561          560     \u001b[91m ☒ \u001b[0m\n",
      "73+586     655          659     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 173us/step - loss: 0.9088 - acc: 0.6752 - val_loss: 0.8870 - val_acc: 0.6761\n",
      "Question   Prediction   Answer\n",
      "777+8      784          785     \u001b[91m ☒ \u001b[0m\n",
      "80+21      103          101     \u001b[91m ☒ \u001b[0m\n",
      "697+253    933          950     \u001b[91m ☒ \u001b[0m\n",
      "40+64      103          104     \u001b[91m ☒ \u001b[0m\n",
      "832+925    1744         1757    \u001b[91m ☒ \u001b[0m\n",
      "682+849    1537         1531    \u001b[91m ☒ \u001b[0m\n",
      "148+874    1035         1022    \u001b[91m ☒ \u001b[0m\n",
      "332+867    1100         1199    \u001b[91m ☒ \u001b[0m\n",
      "99+224     320          323     \u001b[91m ☒ \u001b[0m\n",
      "608+5      611          613     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 178us/step - loss: 0.8345 - acc: 0.7028 - val_loss: 0.8205 - val_acc: 0.7019\n",
      "Question   Prediction   Answer\n",
      "998+108    1106         1106    \u001b[92m ☑ \u001b[0m\n",
      "818+25     849          843     \u001b[91m ☒ \u001b[0m\n",
      "415+60     476          475     \u001b[91m ☒ \u001b[0m\n",
      "868+1      868          869     \u001b[91m ☒ \u001b[0m\n",
      "598+31     628          629     \u001b[91m ☒ \u001b[0m\n",
      "214+96     316          310     \u001b[91m ☒ \u001b[0m\n",
      "20+81      101          101     \u001b[92m ☑ \u001b[0m\n",
      "223+4      228          227     \u001b[91m ☒ \u001b[0m\n",
      "953+825    1776         1778    \u001b[91m ☒ \u001b[0m\n",
      "13+6       18           19      \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 174us/step - loss: 0.7679 - acc: 0.7271 - val_loss: 0.7430 - val_acc: 0.7352\n",
      "Question   Prediction   Answer\n",
      "711+669    1389         1380    \u001b[91m ☒ \u001b[0m\n",
      "825+341    1167         1166    \u001b[91m ☒ \u001b[0m\n",
      "78+71      148          149     \u001b[91m ☒ \u001b[0m\n",
      "354+598    958          952     \u001b[91m ☒ \u001b[0m\n",
      "965+330    1297         1295    \u001b[91m ☒ \u001b[0m\n",
      "893+42     931          935     \u001b[91m ☒ \u001b[0m\n",
      "59+24      80           83      \u001b[91m ☒ \u001b[0m\n",
      "624+37     669          661     \u001b[91m ☒ \u001b[0m\n",
      "31+154     187          185     \u001b[91m ☒ \u001b[0m\n",
      "90+23      114          113     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 168us/step - loss: 0.6754 - acc: 0.7587 - val_loss: 0.6137 - val_acc: 0.7779\n",
      "Question   Prediction   Answer\n",
      "311+267    577          578     \u001b[91m ☒ \u001b[0m\n",
      "134+666    800          800     \u001b[92m ☑ \u001b[0m\n",
      "801+689    1497         1490    \u001b[91m ☒ \u001b[0m\n",
      "209+709    919          918     \u001b[91m ☒ \u001b[0m\n",
      "155+3      158          158     \u001b[92m ☑ \u001b[0m\n",
      "390+33     426          423     \u001b[91m ☒ \u001b[0m\n",
      "58+335     392          393     \u001b[91m ☒ \u001b[0m\n",
      "547+54     501          601     \u001b[91m ☒ \u001b[0m\n",
      "53+837     890          890     \u001b[92m ☑ \u001b[0m\n",
      "828+52     880          880     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.4921 - acc: 0.8311 - val_loss: 0.3917 - val_acc: 0.8741\n",
      "Question   Prediction   Answer\n",
      "13+929     942          942     \u001b[92m ☑ \u001b[0m\n",
      "587+19     607          606     \u001b[91m ☒ \u001b[0m\n",
      "228+1      229          229     \u001b[92m ☑ \u001b[0m\n",
      "67+489     556          556     \u001b[92m ☑ \u001b[0m\n",
      "168+777    954          945     \u001b[91m ☒ \u001b[0m\n",
      "5+304      309          309     \u001b[92m ☑ \u001b[0m\n",
      "221+514    734          735     \u001b[91m ☒ \u001b[0m\n",
      "603+72     675          675     \u001b[92m ☑ \u001b[0m\n",
      "107+244    350          351     \u001b[91m ☒ \u001b[0m\n",
      "234+67     301          301     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.3143 - acc: 0.9141 - val_loss: 0.2672 - val_acc: 0.9329\n",
      "Question   Prediction   Answer\n",
      "8+811      829          819     \u001b[91m ☒ \u001b[0m\n",
      "68+496     564          564     \u001b[92m ☑ \u001b[0m\n",
      "32+20      52           52      \u001b[92m ☑ \u001b[0m\n",
      "698+16     714          714     \u001b[92m ☑ \u001b[0m\n",
      "3+545      548          548     \u001b[92m ☑ \u001b[0m\n",
      "729+897    1626         1626    \u001b[92m ☑ \u001b[0m\n",
      "448+77     525          525     \u001b[92m ☑ \u001b[0m\n",
      "280+455    735          735     \u001b[92m ☑ \u001b[0m\n",
      "10+401     411          411     \u001b[92m ☑ \u001b[0m\n",
      "598+31     639          629     \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 7s 164us/step - loss: 0.2134 - acc: 0.9539 - val_loss: 0.1881 - val_acc: 0.9588\n",
      "Question   Prediction   Answer\n",
      "54+153     207          207     \u001b[92m ☑ \u001b[0m\n",
      "62+62      124          124     \u001b[92m ☑ \u001b[0m\n",
      "5+101      106          106     \u001b[92m ☑ \u001b[0m\n",
      "204+277    481          481     \u001b[92m ☑ \u001b[0m\n",
      "44+44      88           88      \u001b[92m ☑ \u001b[0m\n",
      "101+250    451          351     \u001b[91m ☒ \u001b[0m\n",
      "439+7      446          446     \u001b[92m ☑ \u001b[0m\n",
      "713+909    1622         1622    \u001b[92m ☑ \u001b[0m\n",
      "89+653     742          742     \u001b[92m ☑ \u001b[0m\n",
      "484+24     508          508     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8s 171us/step - loss: 0.1592 - acc: 0.9670 - val_loss: 0.1397 - val_acc: 0.9712\n",
      "Question   Prediction   Answer\n",
      "176+97     273          273     \u001b[92m ☑ \u001b[0m\n",
      "15+99      114          114     \u001b[92m ☑ \u001b[0m\n",
      "197+44     241          241     \u001b[92m ☑ \u001b[0m\n",
      "410+509    919          919     \u001b[92m ☑ \u001b[0m\n",
      "28+66      94           94      \u001b[92m ☑ \u001b[0m\n",
      "584+53     637          637     \u001b[92m ☑ \u001b[0m\n",
      "781+32     813          813     \u001b[92m ☑ \u001b[0m\n",
      "21+183     204          204     \u001b[92m ☑ \u001b[0m\n",
      "44+44      88           88      \u001b[92m ☑ \u001b[0m\n",
      "210+23     233          233     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "Test loss: 0.139680694771\n",
      "Test accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "# Train the model each epoch and show predictions against the validation dataset.\n",
    "for iteration in range(1, 16):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize errors.\n",
    "    print(\"Question   Prediction   Answer\")\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        prediction = ctable.decode(preds[0], calc_argmax=False)\n",
    "        \n",
    "        print(q[::-1] if REVERSE else q, \"  \", prediction, \"       \", correct, \"  \", colors.ok if prediction == correct else colors.fail, \"☑\" if prediction == correct else \"☒\", colors.close)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
